{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precipitaion Forecasting\n",
    "In this project, we have trained different types of machine learning models on some data about weather to predict precipitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "_Weather forecasting_ is using data about the current state and predict how the atmosphere will change. Weather warnings are used to protect lives and property, weather forecasting improves transportation safety, and precipitation forecasting is important to agriculture. There are many different ways of weather prediction. We have used machine learning models and compared the predicted results with actual values.\n",
    "#### Study area\n",
    "Basel is a city in northwest Switzerland. On average $51\\%$ days of the year have precipitation more than $0.1mm$. The total precipitation is around $850 mm$ annually.\n",
    "#### Methodology\n",
    "At first, data is collected. Then, some preprocessing techniques are used to prepare data for machine learning models. Finally, different machine learning techniquies are applied and the accuracy for each is reported.\\\n",
    "The following libraries are used: `numpy`, `pandas`, `matplotlib`, `scikit-learn`, `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdata import get_data, write_daily_data, read_daily_data\n",
    "from preprocessing import drop_missing_data, change_resolution_to_daily, split_data, normalization\n",
    "from visualize import show_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**You can find and download the dataset in [this](https://www.meteoblue.com/en/weather/archive/export) link.**\n",
    "#### About dataset\n",
    "This dataset contains some attributes about weather for Basel, from *January, 2014* to *November, 2023* with hourly resolution. The first nine rows are some basic information about location of city and units of measurements which we do not need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the initial stage, there are $86664$ _samples_ and $7$ parameters.\n",
    "#### Cleaning dataset\n",
    "There are some rows at the end of dataset which are empty, _missing data_. We simply drop them. A day after the missing data is not complete. For simplicity we remove this day as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = drop_missing_data(data)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, number of missing rows is $191$.\n",
    "#### Parameters\n",
    "In our data, each row represents a sample and each column represents a feature. Here is the list of columns\n",
    "- Temperature (*T*)\n",
    "- Precipitation Total (*PT*)\n",
    "- Relative Humidity (*RH*)\n",
    "- Wind Speed (*WS*)\n",
    "- Wind Direction (*WD*)\n",
    "- Cloud Cover Total (*CCT*)\n",
    "- Mean Sea Level Pressure (*MSLP*)\n",
    "\n",
    "measured hourly. This list is raw and we will do some operations to get ready for models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### Make samples daily\n",
    "Forecasting for a whole day is more general than one hour, so we decided to merge each $24$ sample to convert the resolution to daily by get mean for each feature.\n",
    "- Specifically for temperature, having _maximum_, _minimum_, and _mean_ is better.\n",
    "- Precipitation should be the _sum_ instead of _mean_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = change_resolution_to_daily(data)\n",
    "daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have $8$ _features_ and $3603$ _samples_. _PT_ is actually the target value.\\\n",
    "For saving time, we write daily data in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_daily_data(daily_data)\n",
    "_, _, X, y = read_daily_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data\n",
    "We split our data into *train* and *test* sets with relative size $70/30$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "In general, many learning algorithms such as linear models benefit from standardization of the data set.\\\n",
    "We find parameters of nomalization only by having *training set* and **do not** recalculate them on the *test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std = normalization(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize parameters distribution\n",
    "A [histogram](https://www.investopedia.com/terms/h/histogram.asp#:~:text=A%20histogram%20is%20a%20graph,how%20often%20that%20variable%20appears) is a graph that shows the frequency of numerical data using rectangles. The height of each rectangle represents the distribution frequency of a variable. The width of the rectangle represents the value of the variable. Here is the histogram for features and target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying normalization we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "For precipitation forecating, we have two options:\n",
    "- Quantitative Precipitation Forecast (QPF) that foreacst the amount of precipitation.\n",
    "- Predict whether it will rain or not.\n",
    "### Regression\n",
    "We use $R^2$ technique for measuring accuracy.\n",
    "#### Linear Model\n",
    "In this model, target value is expected to be a linear combination of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for Linear Model is about $40$ percent which is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "##### Useful links\n",
    "These links are used in mentioned parts:\n",
    "- [Normalization](https://datascience.stackexchange.com/questions/54908/data-normalization-before-or-after-train-test-split)\n",
    "- [Classification](https://stackoverflow.com/questions/77607029/use-logisticregression-to-predict-precipitation-in-sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
